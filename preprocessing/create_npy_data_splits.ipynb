{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages and data_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 03:20:54.457087: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-14 03:20:55.405241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from climsim_utils.data_utils import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ocean/projects/atm200007p/jlin96/neurips_proj/ClimSim_release\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize folder paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Path/to/training/data/'\n",
    "# replace this with the path to the downloaded training data\n",
    "norm_path = '../norm_factors/'\n",
    "# replace this path if you would like to use your own normalization files\n",
    "grid_path = '../grid_info/E3SM-MMF_ne4_grid-info.orig.nc'\n",
    "# replace this file with the grid info file corresponding to your chosen dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create variables necessary for initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = data_path\n",
    "grid_info = xr.open_dataset(grid_path)\n",
    "inp_mean = xr.open_dataset(norm_path + 'mli_mean.nc')\n",
    "inp_max = xr.open_dataset(norm_path + 'mli_max.nc')\n",
    "inp_min = xr.open_dataset(norm_path + 'mli_min.nc')\n",
    "out_scale = xr.open_dataset(norm_path + 'mlo_scale.nc')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data_utils object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_utils(data_path = data_path, \n",
    "                  grid_info = grid_info, \n",
    "                  inp_mean = inp_mean, \n",
    "                  inp_max = inp_max, \n",
    "                  inp_min = inp_min, \n",
    "                  out_scale = out_scale)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 03:20:58.359697: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "# set inputs and outputs to V1 subset\n",
    "data.set_to_v1_vars()\n",
    "\n",
    "# v1 inputs (name :: description :: dimension :: units): \n",
    "\n",
    "# 'state_t' :: air temperature :: 60 :: K \n",
    "# 'state_q0001' :: specific humidity :: 60 :: kg/kg\n",
    "# 'state_ps' :: surface pressure :: 1 :: Pa\n",
    "# 'pbuf_SOLIN' :: solar insolation :: 1 :: W/m^2\n",
    "# 'pbuf_LHFLX' :: surface latent heat flux :: 1 :: W/m^2\n",
    "# 'pbuf_SHFLX' :: surface sensible heat flux :: 1 :: W/m^2\n",
    "\n",
    "# v1 outputs (name :: description :: dimension :: units): \n",
    "\n",
    "# 'ptend_t' :: heating tendency :: 60 :: K/s \n",
    "# 'ptend_q0001' :: moistening tendency :: 60 :: kg/kg/s\n",
    "# 'cam_out_NETSW' :: net shortwave flux at surface :: 1 :: W/m^2\n",
    "# 'cam_out_FLWDS' :: downward longwave flux at surface :: 1 :: W/m^2 \n",
    "# 'cam_out_PRECSC' :: snow rate (liquid water equivalent) :: 1 :: m/s \n",
    "# 'cam_out_PRECC' :: rain rate :: 1 :: m/s\n",
    "# 'cam_out_SOLS' :: downward visible direct solar flux to surface :: 1 :: W/m^2\n",
    "# 'cam_out_SOLL' :: downward near-infrared direct solar flux to surface :: 1 :: W/m^2\n",
    "# 'cam_out_SOLSD' :: downward diffuse solar flux to surface :: 1 :: W/m^2\n",
    "# 'cam_out_SOLLD' :: downward diffuse near-infrared solar flux to surface :: 1 :: W/m^2\n",
    "\n",
    "# set regular expressions for selecting training data\n",
    "data.set_regexps(data_split = 'train', \n",
    "                 regexps = ['E3SM-MMF.mli.000[1234567]-*-*-*.nc', # years 1 through 7\n",
    "                            'E3SM-MMF.mli.0008-01-*-*.nc']) # first month of year 8\n",
    "# set temporal subsampling\n",
    "data.set_stride_sample(data_split = 'train', stride_sample = 7)\n",
    "# create list of files to extract data from\n",
    "data.set_filelist(data_split = 'train')\n",
    "# save numpy files of training data\n",
    "data.save_as_npy(data_split = 'train', save_path = '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 05:19:01.725068: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "# set regular expressions for selecting validation data\n",
    "data.set_regexps(data_split = 'val',\n",
    "                 regexps = ['E3SM-MMF.mli.0008-0[23456789]-*-*.nc', # months 2 through 9 of year 8\n",
    "                            'E3SM-MMF.mli.0008-1[012]-*-*.nc', # months 10 through 12 of year 8\n",
    "                            'E3SM-MMF.mli.0009-01-*-*.nc']) # first month of year 9\n",
    "# set temporal subsampling\n",
    "data.set_stride_sample(data_split = 'val', stride_sample = 7)\n",
    "# create list of files to extract data from\n",
    "data.set_filelist(data_split = 'val')\n",
    "# save numpy files of validation data\n",
    "data.save_as_npy(data_split = 'val', save_path = '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create scoring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 05:35:01.140716: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "# set regular expressions for selecting scoring data (stride of 6 is needed for daily averaging)\n",
    "data.set_regexps(data_split = 'scoring',\n",
    "                 regexps = ['E3SM-MMF.mli.0008-0[23456789]-*-*.nc', # months 2 through 9 of year 8\n",
    "                            'E3SM-MMF.mli.0008-1[012]-*-*.nc', # months 10 through 12 of year 8\n",
    "                            'E3SM-MMF.mli.0009-01-*-*.nc']) # first month of year 9\n",
    "# set temporal subsampling\n",
    "data.set_stride_sample(data_split = 'scoring', stride_sample = 6)\n",
    "# create list of files to extract data from\n",
    "data.set_filelist(data_split = 'scoring')\n",
    "# save numpy files of scoring data\n",
    "data.save_as_npy(data_split = 'scoring', save_path = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "print('finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
